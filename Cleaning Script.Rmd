---
title: "Tyler Cleaning Script"
author: "Tyler Swanson"
date: "2025-02-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Packages & Import Data
```{r Load Packages & Import Data}

# Load necessary libraries
library(dplyr)
library(tidyr)
library(lubridate)
library(janitor)
library(stringr)

list.files()
getwd()
setwd("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/")

# file.exists("customer_address_and_zip_mapping.csv")
file.exists("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/customer_address_and_zip_mapping.csv")

# file.exists("customer_profile.csv")
file.exists("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/customer_profile.csv")

# file.exists("delivery_cost_data.csv")
file.exists("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/delivery_cost_data.csv")

# file.exists("transactional_data.csv")
file.exists("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/transactional_data.csv")


# customer_address_and_zip_mapping <- read.csv("customer_address_and_zip_mapping.csv", stringsAsFactors = FALSE)
customer_address_and_zip_mapping <- read.csv("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/customer_address_and_zip_mapping.csv")

# customer_profile <- read.csv("customer_profile.csv", stringsAsFactors = FALSE)
customer_profile <- read.csv("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/customer_profile.csv")

# delivery_cost_data <- read.csv("delivery_cost_data.csv", stringsAsFactors = FALSE)
delivery_cost_data <- read.csv("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/delivery_cost_data.csv")

# transactional_data <- read.csv("transactional_data.csv", stringsAsFactors = FALSE)
transactional_data <- read.csv("C:/Users/Tyler.Swanson/OneDrive - PDQ.com/Documents/University of Utah - MSBA/Spring 2025/IS 6813 - MSBA Capstone Case Comp/Swire Data/delivery-standardization-group/transactional_data.csv")


```


# Prep delivery_cost_data 
```{r delivery_cost_data}


# Clean column names
delivery_cost_data <- clean_names(delivery_cost_data)

# Check column names again to verify correct names
colnames(delivery_cost_data)

# Split 'vol_range' into 'min_cost_vol' & 'max_cost_vol'
delivery_cost_data <- delivery_cost_data %>%
  separate(vol_range, into = c("min_cost_vol", "max_cost_vol"), sep = " - ", fill = "right", extra = "drop") %>%
  mutate(
    min_cost_vol = as.integer(min_cost_vol),  # Convert to integer
    max_cost_vol = as.integer(max_cost_vol),  # Convert to integer
    median_delivery_cost = as.numeric(gsub("[$,]", "", median_delivery_cost))  # Clean currency symbols
  )

# Update missing values
delivery_cost_data <- delivery_cost_data %>%
  group_by(cold_drink_channel, applicable_to) %>%
  mutate(
    min_cost_vol = ifelse(is.na(min_cost_vol), max(max_cost_vol, na.rm = TRUE) + 1, min_cost_vol),  # Set min to max + 1
    max_cost_vol = ifelse(is.na(max_cost_vol), 100000, max_cost_vol)  # Set max to 100,000
  ) %>%
  ungroup()

# View cleaned delivery cost data
str(delivery_cost_data)
head(delivery_cost_data)
# filter(delivery_cost_data, is.na(min_cost_vol) | is.na(max_cost_vol))
```




# Prep customer_address Object
```{r Prep customer_address Object}

colnames(customer_address_and_zip_mapping)
glimpse(customer_address_and_zip_mapping)
head(customer_address_and_zip_mapping)


# Split 'full.address' column
customer_address_and_zip_mapping <- customer_address_and_zip_mapping %>%
  separate(full.address, into = c("ZIP_CODE", "city", "state", "state_abbr", "county", "unknown", "lat", "lon"), sep = ",", extra = "drop") %>%
  select(-unknown) %>%
  mutate(
    ZIP_CODE = as.character(ZIP_CODE),
    lat = as.numeric(lat),
    lon = as.numeric(lon)
  )

 customer_address_and_zip_mapping <- customer_address_and_zip_mapping %>%
   select(-zip)

# View cleaned address data
str(customer_address_and_zip_mapping)
head(customer_address_and_zip_mapping)

```


# Combine Data
```{r Combine Data}


customer_profile <- customer_profile %>%
  mutate(ZIP_CODE = str_pad(as.character(ZIP_CODE), width = 5, side = "left", pad = "0"))

# Verify the change
table(nchar(customer_profile$ZIP_CODE))  # Ensure all values have length 5

# Convert key identifiers to character
customer_profile <- customer_profile %>%
  mutate(
    CUSTOMER_NUMBER = as.character(CUSTOMER_NUMBER),
    PRIMARY_GROUP_NUMBER = as.character(PRIMARY_GROUP_NUMBER),
    ZIP_CODE = as.character(ZIP_CODE)
  )

transactional_data <- transactional_data %>%
  mutate(
    CUSTOMER_NUMBER = as.character(CUSTOMER_NUMBER),
    YEAR = as.integer(YEAR),
    # Ensure DELIVERED_TOTAL exists before counting negative deliveries
    DELIVERED_TOTAL = DELIVERED_CASES + DELIVERED_GALLONS
  )

# Count negative deliveries per customer per year
neg_deliveries <- transactional_data %>%
  group_by(CUSTOMER_NUMBER, YEAR) %>%
  summarise(neg_deliveries = sum(DELIVERED_TOTAL < 0, na.rm = TRUE), .groups = "drop")

# Merge customer profile with transactional data
merged_data <- transactional_data %>%
  left_join(customer_profile, by = "CUSTOMER_NUMBER") %>%
  left_join(customer_address_and_zip_mapping, by = "ZIP_CODE") %>%
  left_join(neg_deliveries, by = c("CUSTOMER_NUMBER", "YEAR")) %>%
  left_join(
    delivery_cost_data, 
    by = join_by(COLD_DRINK_CHANNEL == cold_drink_channel, 
                 between(DELIVERED_TOTAL, min_cost_vol, max_cost_vol))
  )

filtered_data <- merged_data %>% 
  filter(DELIVERED_TOTAL >= 0)


merged_data <- merged_data %>%
  # Ensure applicable_to is not NA before grouping
  filter(!is.na(applicable_to)) %>%
  group_by(COLD_DRINK_CHANNEL, applicable_to) %>%
  mutate(
    min_cost_vol = ifelse(is.na(min_cost_vol), max(max_cost_vol, na.rm = TRUE) + 1, min_cost_vol),
    max_cost_vol = ifelse(is.na(max_cost_vol), 100000, max_cost_vol),
    median_delivery_cost = ifelse(is.na(median_delivery_cost), mean(median_delivery_cost, na.rm = TRUE), median_delivery_cost)
  ) %>%
  ungroup()

# Remove duplicate rows based on customer_number, transaction_date, ordered_cases, and ordered_gallons
# merged_data <- merged_data %>%
#  distinct(customer_number, transaction_date, ordered_cases, ordered_gallons, .keep_all = TRUE)

# Remove duplicates based on the specified columns
merged_data <- merged_data %>% 
  distinct(TRANSACTION_DATE, WEEK, YEAR, CUSTOMER_NUMBER, 
           ORDERED_CASES, ORDERED_GALLONS, .keep_all = TRUE)

# View merged data
str(merged_data)
head(merged_data)

```




# Standardize Column Names & Data Types
```{r Standardize Column Names & Data Types}

# Standardize column names
merged_data <- merged_data %>% clean_names()

# Convert date fields
merged_data <- merged_data %>%
  mutate(
    transaction_date = mdy(transaction_date),
    first_delivery_date = mdy(first_delivery_date),
    on_boarding_date = mdy(on_boarding_date),
    customer_number = as.character(customer_number),
    primary_group_number = as.character(primary_group_number),
    zip_code = as.character(zip_code)
  )

# Convert categorical fields to factors
merged_data <- merged_data %>%
  mutate(
    cold_drink_channel = as.factor(cold_drink_channel),
    frequent_order_type = as.factor(frequent_order_type),
    trade_channel = as.factor(trade_channel),
    sub_trade_channel = as.factor(sub_trade_channel),
    order_type = as.factor(order_type),
    local_market_partner = as.logical(local_market_partner),
    co2_customer = as.logical(co2_customer)
  )

# View structure after cleaning
str(merged_data)
head(merged_data)


```



# Handle Negative Deliveries (Returns)
```{r Negative Deliveries}
# Count negative deliveries per customer per year
neg_deliveries <- transactional_data %>%
  group_by(CUSTOMER_NUMBER, YEAR) %>%
  summarise(neg_deliveries = sum(DELIVERED_TOTAL < 0, na.rm = TRUE), .groups = "drop")

# Merge with main dataset
merged_data <- merged_data %>%
  left_join(neg_deliveries, by = c("customer_number" = "CUSTOMER_NUMBER", "year" = "YEAR"))

# View updated dataset
str(merged_data)
head(merged_data)


```
 

# Count Customers per Group
```{r Count Customers per Group}
# Count customers per primary group per year
customer_group_count <- merged_data %>%
  group_by(primary_group_number, year) %>%
  summarise(customer_count = n(), .groups = "drop")

# Merge with dataset
merged_data <- merged_data %>%
  left_join(customer_group_count, by = c("primary_group_number", "year"))

# View updated dataset
str(merged_data)
head(merged_data)

```


# Review
```{r Review}
# Show summary of final cleaned dataset

Swire_Master_Data <- merged_data

# Remove duplicates based on the specified columns
Swire_Master_Data <- Swire_Master_Data %>% 
  distinct(transaction_date, week, year, customer_number, 
           ordered_cases, loaded_cases, delivered_cases, 
           ordered_gallons, loaded_gallons, .keep_all = TRUE)

# Check the updated dataset
# dim(Swire_Master_Data)  # New dimensions after removing duplicates
head(Swire_Master_Data) # Preview first few rows
# str(Swire_Master_Data)
# head(Swire_Master_Data)


glimpse(Swire_Master_Data)
summary(Swire_Master_Data)

sum(is.na(Swire_Master_Data$min_cost_vol))  
sum(is.na(Swire_Master_Data$max_cost_vol))  
sum(is.na(Swire_Master_Data$median_delivery_cost))



# Define file path
# file_path <- "Swire_Master_Data.csv"

# Export as CSV
# write.csv(Swire_Master_Data, file = file_path, row.names = FALSE)

# Confirm file creation
# if (file.exists(file_path)) {
#   print(paste("File successfully saved at:", file_path))
# } else {
#   print("Error: File was not created.")
# }



```

